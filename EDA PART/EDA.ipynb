{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852dc02-fb09-4896-bfe4-05d3f70ac956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "\n",
    "df.head()\n",
    "\n",
    "df1=df[[\"Stage_fear\",\"Drained_after_socializing\"]]\n",
    "\n",
    "df=df1\n",
    "\n",
    "df['Stage_fear'] = df['Stage_fear'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "\n",
    "df['Drained_after_socializing'] = df['Drained_after_socializing'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer  # Must include this\n",
    "from sklearn.impute import IterativeImputer\n",
    "import numpy as np\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "\n",
    "# Impute (returns a NumPy array)\n",
    "likes_imputed = imputer.fit_transform(df[['Stage_fear']])\n",
    "\n",
    "imputer1 = IterativeImputer(max_iter=10, random_state=0)\n",
    "\n",
    "# Impute (returns a NumPy array)\n",
    "likes_imputed1 = imputer1.fit_transform(df[['Drained_after_socializing']])\n",
    "\n",
    "# Round the values (IterativeImputer may predict values like 0.47, 0.91)\n",
    "df['Stage_fear1'] = np.round(likes_imputed).astype(int)\n",
    "\n",
    "\n",
    "# Round the values (IterativeImputer may predict values like 0.47, 0.91)\n",
    "df['Drained_after_socializing1'] = np.round(likes_imputed1).astype(int)\n",
    "\n",
    "\n",
    "df\n",
    "\n",
    "df[\"Stage_fear1\"].value_counts()\n",
    "\n",
    "df[\"Stage_fear\"].value_counts()\n",
    "\n",
    "df[\"Drained_after_socializing\"].value_counts()\n",
    "\n",
    "df[\"Drained_after_socializing1\"].value_counts()\n",
    "\n",
    "df.to_csv(\"new_df\")\n",
    "\n",
    "df2=pd.read_csv(\"train.csv\")\n",
    "\n",
    "df2.head()\n",
    "\n",
    "df2 = df2.drop(columns=[\"Drained_after_socializing\",\"Stage_fear\"])\n",
    "\n",
    "df2\n",
    "\n",
    "df3 = pd.concat([df2,df],axis=1)\n",
    "\n",
    "df3 = df3.drop([\"Personality\"],axis=1)\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "\n",
    "# Fit and transform all columns\n",
    "df_imputed_array = imputer.fit_transform(df3)\n",
    "\n",
    "# Put back into DataFrame\n",
    "df_imputed = pd.DataFrame(df_imputed_array, columns=df3.columns)\n",
    "\n",
    "df_imputed \n",
    "\n",
    "\n",
    "\n",
    "df_clean = df3.dropna()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create a corrupted version of the clean data\n",
    "df_corrupted = df_clean.copy()\n",
    "mask = np.random.rand(*df_clean.shape) < 0.1  # 10% values set to NaN\n",
    "df_corrupted[mask] = np.nan\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imputer = IterativeImputer(random_state=42)\n",
    "df_imputed = imputer.fit_transform(df_corrupted)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(df_clean.values.flatten(), df_imputed.flatten())\n",
    "mae = mean_absolute_error(df_clean.values.flatten(), df_imputed.flatten())\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(df_clean.values.flatten(), df_imputed.flatten())\n",
    "mae = mean_absolute_error(df_clean.values.flatten(), df_imputed.flatten())\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "\n",
    "df3.corr()\n",
    "\n",
    "df3\n",
    "\n",
    "df_imputed\n",
    "\n",
    "df_imputed = df_imputed.drop(['Drained_after_socializing','Stage_fear'],axis=1)\n",
    "\n",
    "df_imputed.corr()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "test = test.dropna()\n",
    "\n",
    "test\n",
    "\n",
    "test.to_csv(\"test_data.csv\")\n",
    "\n",
    "test.rename(columns={'Drained_after_socializing': 'Drained_after_socializing1'}, inplace=True)\n",
    "\n",
    "test.rename(columns={'Stage_fear': 'Stage_fear1'}, inplace=True)\n",
    "\n",
    "test = test.drop('id',axis=1)\n",
    "\n",
    "test\n",
    "\n",
    "test['Stage_fear1'] = test['Stage_fear1'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "\n",
    "test['Drained_after_socializing1'] = test['Drained_after_socializing1'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "\n",
    "test.head()\n",
    "\n",
    "test\n",
    "\n",
    "test.to_csv(\"test_data1.csv\")\n",
    "\n",
    "test.dtypes\n",
    "\n",
    "sample=pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "sample\n",
    "\n",
    "sample[\"Personality\"].value_counts()\n",
    "\n",
    "test1 = pd.read_csv(\"test.csv\")\n",
    "\n",
    "result = pd.concat([test1,sample],axis=1)\n",
    "\n",
    "result\n",
    "\n",
    "result.dropna(inplace=True)\n",
    "\n",
    "result\n",
    "\n",
    "result[\"Personality\"].value_counts()\n",
    "\n",
    "test1\n",
    "\n",
    "chatgpt=pd.read_csv(\"chatgpt.csv\")\n",
    "\n",
    "chatgpt = chatgpt.drop(['Personality'],axis=1)\n",
    "\n",
    "chatgpt\n",
    "\n",
    "chatgpt.to_csv(\"test_chatgpt.csv\")\n",
    "\n",
    "test1\n",
    "\n",
    "test1.isnull().sum()\n",
    "\n",
    "\n",
    "test1['Stage_fear1'] = test1['Stage_fear'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "\n",
    "test1['Drained_after_socializing1'] = test1['Drained_after_socializing'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "\n",
    "test1\n",
    "\n",
    "test1 = test1.drop(['Stage_fear','Drained_after_socializing'],axis=1)\n",
    "\n",
    "test1\n",
    "\n",
    "test1['Stage_fear1'].value_counts()\n",
    "\n",
    "test2=test1[['Stage_fear1','Drained_after_socializing1']]\n",
    "\n",
    "test3=test1[['Time_spent_Alone','Social_event_attendance','Going_outside','Friends_circle_size','Post_frequency']]\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "\n",
    "# Impute (returns a NumPy array)\n",
    "likes_imputed = imputer.fit_transform(test2[['Stage_fear1','Drained_after_socializing1']])\n",
    "\n",
    "# Round the values (IterativeImputer may predict values like 0.47, 0.91)\n",
    "test2[['Stage_fear1','Drained_after_socializing1']] = np.round(likes_imputed).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test3\n",
    "\n",
    "for col in test3.columns:\n",
    "    if test3[col].dtype in ['float64', 'int64']:  # Only for numeric columns\n",
    "        mean_val = test3[col].mean()\n",
    "        test3[col].replace(to_replace=np.nan, value=mean_val, inplace=True)\n",
    "\n",
    "test3\n",
    "\n",
    "final_test=pd.concat([test2,test3],axis=1)\n",
    "final_test\n",
    "\n",
    "final_test.to_csv(\"final_test.csv\")\n",
    "\n",
    "test_data_final = pd.read_csv(\"test_data_with_predictions.csv\")\n",
    "\n",
    "test_data_final\n",
    "\n",
    "test1\n",
    "\n",
    "test_final = pd.concat([test1['id'],test_data_final['Predicted_Personality']],axis=1)\n",
    "\n",
    "test_final\n",
    "\n",
    "test_final.to_csv(\"test_final.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
